{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crime = pd.read_csv('FE1_NYPD_Complaint_Data_Historic.csv') # read in the csv %%file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create categorical list of all 68 possible offenses\n",
    "#4 types of crime: Personal, Property, Statutory/State, and Other\n",
    "\n",
    "#Personal - Assault, Battery, Abuse, Kidnapping, Rape, Homicide, Harrassment\n",
    "personal_list = ['ASSAULT', 'BATTERY', 'MURDER', 'MANSLAUGHTER', 'HARRASSMENT', 'KIDNAPPING', 'RAPE', 'SEX', 'HOMICIDE', 'WEAPON', 'WEAPONS', 'PERSON']\n",
    "\n",
    "#Property - Arson, Theft, Mischief, Burglary, Larceny, Robbery, Forgery, Embezzlement, Shoplifting, Trespass, Fraud/Financial\n",
    "property_list = ['ARSON', 'THEFT', 'THEF', 'MISCHIEF', 'ROBBERY', 'BURGLARY', 'JOSTLING', 'TOOLS', 'FRAUD', 'FRAUDS', 'FRAUDULENT', 'LARCENY', 'FORGERY', 'STOLEN', 'UNAUTHORIZED', 'TRESPASS']\n",
    "\n",
    "#Statutory - State-Related offenses, DUI, DWI, Gambling, Loitering, Drug, Traffic, Public Servant/Admin-related crimes\n",
    "statutory_list = ['DRUGS', 'DRUG', 'SENSBLTY', 'PENAL', 'PUBLIC', 'INTOXICATED', 'TRAFFIC', 'ADMINISTRATIVE', 'GAMBLING', 'PROSTITUTION', 'ALCOHOLIC', 'DISORDERLY']\n",
    "\n",
    "#Violent vs Non-Violent\n",
    "violent = personal_list\n",
    "non_violent = property_list + statutory_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all Hyphons and forward slashes with spaces\n",
    "def string_replace(column):\n",
    "    \n",
    "    newstrings = []\n",
    "    \n",
    "    for string in column:\n",
    "        for word in string:\n",
    "            if word == '-':\n",
    "                newstrings.append(string.replace('-', ' '))\n",
    "                break\n",
    "            elif word == '/':\n",
    "                newstrings.append(string.replace('/', ' '))\n",
    "                break\n",
    "        else:\n",
    "            newstrings.append(string)\n",
    "                \n",
    "    \n",
    "    return ''.join(newstrings)\n",
    "\n",
    "def crime_apply(string):\n",
    "    \n",
    "    for word in string.split():\n",
    "        if word in personal_list:\n",
    "            return \"Personal Crime\"\n",
    "        elif word in property_list:\n",
    "            return \"Property Crime\"\n",
    "        elif word in statutory_list:\n",
    "            return \"Statutory Crime\"\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the function to create the correct buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NA's before applying Algo.. only removes about 2-3k observations\n",
    "crime = crime[crime['OFNS_DESC'].notna()] \n",
    "crime['OFNS_DESC'] = crime.apply(lambda x: string_replace(x['OFNS_DESC']), axis = 1)\n",
    "crime['OFNS_DESC_TYPE'] = crime.apply(lambda x: crime_apply(x['OFNS_DESC']), axis = 1)\n",
    "crime.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value Counts by Crime Type\n",
    "crime['OFNS_DESC_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the variables that are extraneous or duplicitous based on EDA\n",
    "if 'CMPLNT_FR_DT' in crime:\n",
    "    del crime['CMPLNT_FR_DT']\n",
    "if 'CMPLNT_FR_TM' in crime:\n",
    "    del crime['CMPLNT_FR_TM']\n",
    "if 'CMPLNT_TO_DT' in crime:\n",
    "    del crime['CMPLNT_TO_DT']\n",
    "if 'CMPLNT_TO_TM' in crime:\n",
    "    del crime['CMPLNT_TO_TM']    \n",
    "if 'PARKS_NM' in crime:\n",
    "    del crime['PARKS_NM'] \n",
    "if 'HADEVELOPT' in crime:\n",
    "    del crime['HADEVELOPT']      \n",
    "if 'End_Dt_Tm' in crime:\n",
    "    del crime['End_Dt_Tm']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'CMPLNT_NUM' in crime:\n",
    "    del crime['CMPLNT_NUM']\n",
    "if 'KY_CD' in crime:\n",
    "    del crime['KY_CD']\n",
    "if 'RPT_DT' in crime:\n",
    "    del crime['RPT_DT']\n",
    "if 'PD_CD' in crime:\n",
    "    del crime['PD_CD']\n",
    "if 'PD_DESC' in crime:\n",
    "    del crime['PD_DESC']\n",
    "if 'X_COORD_CD' in crime:\n",
    "    del crime['X_COORD_CD']\n",
    "if 'Y_COORD_CD' in crime:\n",
    "    del crime['Y_COORD_CD']\n",
    "if 'Latitude' in crime:\n",
    "    del crime['Latitude']\n",
    "if 'Longitude' in crime:\n",
    "    del crime['Longitude']\n",
    "if 'Lat_Lon' in crime:\n",
    "    del crime['Lat_Lon']\n",
    "if 'OFNS_DESC' in crime:\n",
    "    del crime['OFNS_DESC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any remaining NANs\n",
    "crime = crime.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the data into predictors and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = crime[['JURIS_DESC','BORO_NM','ADDR_PCT_CD','LOC_OF_OCCUR_DESC','PREM_TYP_DESC','Day_Name','Duration','Duration_to_PD','Month','Day','Year','Duration_lbl','Season','Daytime','GeoCell','GeoCell_X','GeoCell_Y']]\n",
    "y = crime[['OFNS_DESC_TYPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dummy variables for categoricals\n",
    "cat_vars=['JURIS_DESC','BORO_NM','LOC_OF_OCCUR_DESC','ADDR_PCT_CD','PREM_TYP_DESC','Day_Name','Month','Duration_lbl','Season','Daytime']\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(X[var], prefix=var)\n",
    "    data1=X.join(cat_list)\n",
    "    X=data1\n",
    "\n",
    "data_vars=X.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "#keep only the non-categoricals and the new dummy variables\n",
    "X = X[to_keep]\n",
    "X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "X = crime[['JURIS_DESC','BORO_NM','ADDR_PCT_CD','LOC_OF_OCCUR_DESC','PREM_TYP_DESC','Day_Name','Duration','Duration_to_PD','Month','Day','Year','Duration_lbl','Season','Daytime','GeoCell','GeoCell_X','GeoCell_Y']]\n",
    "y = crime[['OFNS_DESC_TYPE']]\n",
    "\n",
    "columns_to_encode = ['JURIS_DESC','BORO_NM','LOC_OF_OCCUR_DESC','ADDR_PCT_CD','PREM_TYP_DESC','Day_Name','Month','Duration_lbl','Season','Daytime']\n",
    "columns_to_scale = ['Duration','Duration_to_PD']\n",
    "columns_no_change = ['Day','Year','GeoCell','GeoCell_X','GeoCell_Y']\n",
    "\n",
    "df_existing = X[columns_no_change]\n",
    "existing_cols = df_existing.to_numpy()\n",
    "\n",
    "#encoder and scaler\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "#scale and encode separate columns\n",
    "scaled_columns = scaler.fit_transform(X[columns_to_scale])\n",
    "encoded_columns = ohe.fit_transform(X[columns_to_encode])\n",
    "\n",
    "#concatenate processed columns back together\n",
    "X_np = np.concatenate([scaled_columns,encoded_columns,existing_cols],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the numpy array back to a pandas dataframe\n",
    "df1 = pd.DataFrame(X_np)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the column names back to the dataframe\n",
    "feature_names = ohe.get_feature_names().tolist()\n",
    "#df = pd.DataFrame(feature_names)\n",
    "#df = df.T\n",
    "col_names = columns_to_scale+feature_names+columns_no_change\n",
    "col_names\n",
    "df1.columns = col_names\n",
    "X = df1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/classification/plot_classification_probability.html#sphx-glr-auto-examples-classification-plot-classification-probability-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "\n",
    "C = 10\n",
    "kernel = 1.0 * RBF([1.0, 1.0])  # for GPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'L1 logistic': LogisticRegression(C=C, penalty='l1',\n",
    "                                      solver='saga',\n",
    "                                      multi_class='multinomial',\n",
    "                                      max_iter=10000),\n",
    "    'L2 logistic (Multinomial)': LogisticRegression(C=C, penalty='l2',\n",
    "                                                    solver='saga',\n",
    "                                                    multi_class='multinomial',\n",
    "                                                    max_iter=10000),\n",
    "    'L2 logistic (OvR)': LogisticRegression(C=C, penalty='l2',\n",
    "                                            solver='saga',\n",
    "                                            multi_class='ovr',\n",
    "                                            max_iter=10000),\n",
    " #   'Linear SVC': SVC(kernel='linear', C=C, probability=True,\n",
    " #                     random_state=0),\n",
    " #   'GPC': GaussianProcessClassifier(kernel)\n",
    "}\n",
    "\n",
    "n_classifiers = len(classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3 * 2, n_classifiers * 2))\n",
    "plt.subplots_adjust(bottom=.2, top=.95)\n",
    "\n",
    "xx = np.linspace(3, 9, 100)\n",
    "yy = np.linspace(1, 5, 100).T\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "Xfull = np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X, y)\n",
    "\n",
    "    y_pred = classifier.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # View probabilities:\n",
    "    probas = classifier.predict_proba(Xfull)\n",
    "    n_classes = np.unique(y_pred).size\n",
    "    for k in range(n_classes):\n",
    "        plt.subplot(n_classifiers, n_classes, index * n_classes + k + 1)\n",
    "        plt.title(\"Class %d\" % k)\n",
    "        if k == 0:\n",
    "            plt.ylabel(name)\n",
    "        imshow_handle = plt.imshow(probas[:, k].reshape((100, 100)),\n",
    "                                   extent=(3, 9, 1, 5), origin='lower')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        idx = (y_pred == k)\n",
    "        if idx.any():\n",
    "            plt.scatter(X[idx, 0], X[idx, 1], marker='o', c='w', edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes([0.15, 0.04, 0.7, 0.05])\n",
    "plt.title(\"Probability\")\n",
    "plt.colorbar(imshow_handle, cax=ax, orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
